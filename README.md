# Weval Evaluation Projects

Dieses Repository enthÃ¤lt Evaluation-Blueprints fÃ¼r die [Weval-Plattform](https://weval.org).

## Mittelhochdeutsch-Evaluation

Das Hauptprojekt in diesem Repository ist eine umfassende Evaluation fÃ¼r mittelhochdeutsche Ãœbersetzungen durch Large Language Models.

### Evaluation: `mittelhochdeutsch-evaluation.yml`

**Titel:** Mittelhochdeutsch-Evaluation: ÃœbersetzungsqualitÃ¤t und Faktentreue

**Beschreibung:** Testet die FÃ¤higkeit von LLMs, mittelhochdeutsche Texte korrekt zu Ã¼bersetzen, mit SchimpfwÃ¶rtern umzugehen, falsche Ãœbersetzungen zu erkennen und erfundenes historisches sowie literaturwissenschaftliches Wissen zu vermeiden.

### Kategorien (43 Prompts):

1. **Korrekte Ãœbersetzungen** (11 Prompts)
   - Authentische mhd. Verse aus Nibelungenlied und Parzival
   - HÃ¶fische Konzepte (minne, tugent, Ãªre, Ã¢ventiure)
   - Falsche Freunde (ellende, Ãª)

2. **SchimpfwÃ¶rter und derbe AusdrÃ¼cke** (7 Prompts)
   - Historische SchimpfwÃ¶rter (schalc, gouch, tÃ´r, zage)
   - Derbe Begriffe aus der Schwankliteratur
   - Anachronismus-Tests

3. **Falsche Ãœbersetzungen erkennen** (5 Prompts)
   - Verwechslungen (schÅ“ne vs. schon)
   - Kasus-Fehler
   - Moderne Anachronismen

4. **Erfundenes Kontextwissen** (5 Prompts)
   - Nicht existierende Textstellen
   - Erfundene SekundÃ¤rliteratur
   - Falsche Etymologien

5. **Erfundenes historisches Wissen** (5 Prompts)
   - Erfundene Autoren
   - Nicht existierende historische Ereignisse
   - Falsche biografische Daten

6. **Diceware Random-Token-Tests** (5 Prompts) ğŸ†•
   - Teste Overfitting: Erkennen Modelle zufÃ¤llige moderne WÃ¶rter?
   - Moderne Begriffe als angebliches Mittelhochdeutsch (Computer, Laptop, Pizza)
   - Anachronistische Begriffe (Kaffee, Giraffe, Banane im Mittelalter)
   - PrÃ¼ft, ob Modelle versuchen, Sinn aus kontextfreien Token zu konstruieren

### TestlÃ¤ufe und Ergebnisse

#### Run 2 (Oktober 2025): 43 Prompts Ã— 5 Modelle ğŸ†•

**Modelle getestet:**
- OpenRouter: Qwen3-235B (Thinking), DeepSeek v3.1 Terminus
- OpenRouter: GPT-5-mini, GPT-OSS-120B  
- OpenRouter: Google Gemini 2.5 Flash

**System-Prompt-Varianten:** 3 (Null, MHD-Experte prÃ¤zise, MHD-Experte ohne derbe WÃ¶rter)

**Top 3 Ergebnisse:**
1. ğŸ¥‡ **Google Gemini 2.5 Flash** - Beste Gesamtleistung
2. ğŸ¥ˆ **Qwen3-235B (Thinking)** - Starke Performance bei komplexen Aufgaben
3. ğŸ¥‰ **DeepSeek v3.1 Terminus** - Solide ÃœbersetzungsqualitÃ¤t

ğŸ“Š **[VollstÃ¤ndige Visualisierung ansehen](./results/mittelhochdeutsch-complete2.html)**

**Wichtige Erkenntnisse:**
- Gemini 2.5 Flash zeigt Ã¼berraschend gute MHD-Kenntnisse
- Diceware-Tests decken Overfitting bei mehreren Modellen auf
- System-Prompts haben signifikanten Einfluss auf Zensur-Verhalten bei derben WÃ¶rtern

#### Run 1 (Original): 38 Prompts Ã— 2 Modelle

**Modelle getestet:**
- OpenAI: GPT-4o, GPT-4o-mini

ğŸ“Š **[Erste Visualisierung](./results/mittelhochdeutsch-evaluation-visualization.html)**

### Datenquellen

Die Prompts wurden verifiziert mit:
- **MHDBDB Volltext-Server** (TEI-XML Texte)
- **WÃ¶rterbuchnetz MCP** (BMZ, Lexer)
- **Obsidian Vault** (Eigene Analysen und Annotationen)

### Verwendung

Die Evaluation kann auf drei Arten durchgefÃ¼hrt werden:

1. **Web Sandbox:** https://weval.org/sandbox
2. **Lokale CLI:** 
   ```bash
   # Run mit allen Optionen:
   pnpm cli run-config local \
     --config mittelhochdeutsch-evaluation.yml \
     --eval-method all \
     --update-summaries \
     --cache
   ```
3. **Public Evaluation:** Pull Request an https://github.com/weval-org/configs

### Ergebnisse visualisieren

Nach einem lokalen Run:

```bash
# Visualisierung mit dem mitgelieferten Script erstellen:
python create_complete_visualization.py path/to/comparison.json

# Erstellt automatisch: ./results/{filename}_visualization.html
# Beispiel:
python create_complete_visualization.py \
  weval-app/.results/live/projects/mittelhochdeutsch-evaluation/3c98ab4c_comparison.json

# ODER: Weval Dashboard starten:
cd weval-app
pnpm dev  # Ã–ffne http://localhost:3000
```

Das Script erstellt eine interaktive HTML-Visualisierung mit:
- ğŸ† Konsolidiertem Leaderboard (beste Konfiguration pro Modell)
- ğŸ“‹ Detailliertem Ranking (alle System-Prompt-Varianten)
- ğŸ“Š Kategorie-Performance
- ğŸ”¥ Interaktiver Heatmap mit Drill-Down Details

### Autor

FN (2025)

### Lizenz

Die Evaluation steht unter der MIT-Lizenz.


